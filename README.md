# Scraper
AI Core Project 3 - Data Collection Pipeline

The purpose of the Data Collection Pipeline project is to automate the collection of data from a chosen website.

In this case, the website of Screwfix, the home improvement supplies company was chosen.

This choice was made for two reasons: first, that it contains a lot of data suitable for collection; and second, because it's a website
that I use frequently and any search tools that I develop may be of actual use to me.

The code defines a Scraper class with multiple methods that define a logical sequence for the collection of data from the site.

In sequence, the methods are as follows:

open_url: to open the specified website, in this case www.screwfix.com

cookies_check: to check whether the website is requiring cookies to be accepted and to accept them if so.

initial_search: to enter a desired search term into the search bar. The search term is provided as the argument to the main function.

get_sub_category_list: certain broad search terms don't give individual products as the result but instead take the user to
a second page with sub-categories into which the initial search term can fall. For example, a search for "power tools" will
yield a page showing categories such as drills, saws, drivers etc. This method will return a list containing these sub-categories,
if they exist, or an empty list if not.

get_sub_category_choice: if the initial search resulted in sub-categories then this method will advise the user of this fact and prompt
for a choice of sub-category to be made.

get_product_links: by this point in the code's execution, the browser will be on a page displaying a table of individual products, each entry
of which will show summary information about the product. This method will generate a list of links to the detailed product pages.

get_product_features_table: this method will visit the detailed product page for each item in turn using the list of product page links
generated by get_product_links. On landing a product page the browser will navigate to the product Specifications tab and extract the
data contained therein into a list.

export_json: export extracted data as a JSON dictionary.

transform_product_table: even for products in the same category on the website, the data fields contained in the specifications are not
exactly the same for each product. To ensure consistency between products, the data previously extracted is transformed so that all possible
specification fields are represented for every product in the date capture. In cases where a product does not have particular data field,
this field will be marked as "N/A". The data is then output to a csv file.

The main function calls these methods in the specified sequence by which the desired data is collected from the website.
The function takes a single argument, that being the item to be searched for.
